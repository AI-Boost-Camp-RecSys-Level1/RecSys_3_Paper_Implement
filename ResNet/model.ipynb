{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from blocks import BottleneckResidualBlock, ResidualBlock\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(\n",
    "    './data', \n",
    "    train=True, \n",
    "    transform=torchvision.transforms.ToTensor(), \n",
    "    download=True\n",
    "    )\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=5, shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(dataloader))\n",
    "data.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBase(nn.Module):\n",
    "    \"\"\"Some Information about ResNetBase\"\"\"\n",
    "    def __init__(self, n_blocks: List[int], n_channels: List[int],\n",
    "                 bottlenecks: Optional[List[int]] = None,\n",
    "                 img_channels: int = 3, first_kernel_size: int = 7):\n",
    "        super(ResNetBase, self).__init__()\n",
    "        assert len(n_blocks) == len(n_channels)\n",
    "        assert bottlenecks is None or len(bottlenecks) == len(n_channels)\n",
    "        self.conv = nn.Conv2d(img_channels, n_channels[0],\n",
    "                              kernel_size=first_kernel_size, stride=2, padding=first_kernel_size // 2)\n",
    "        self.bn = nn.BatchNorm2d(n_channels[0])\n",
    "        blocks = []\n",
    "        prev_channels = n_channels[0]\n",
    "        for i, channels in enumerate(n_channels):\n",
    "            stride = 2 if len(blocks) == 0 else 1\n",
    "            if bottlenecks is None:\n",
    "                blocks.append(ResidualBlock(prev_channels, channels, stride=stride))\n",
    "            else:\n",
    "                blocks.append(BottleneckResidualBlock(prev_channels, bottlenecks[i], channels,\n",
    "                                                      stride=stride))\n",
    "            prev_channels = channels\n",
    "            for _ in range(n_blocks[i] - 1):\n",
    "                if bottlenecks is None:\n",
    "                    blocks.append(ResidualBlock(channels, channels, stride=1))\n",
    "                else:\n",
    "                    blocks.append(BottleneckResidualBlock(channels, bottlenecks[i], channels, stride=1))\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.bn(self.conv(x))\n",
    "        x = self.blocks(x)\n",
    "        x = x.view(x.shape[0], x.shape[1], -1)\n",
    "        \n",
    "        return x.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_blocks = [2,2,2,2]\n",
    "n_channels = [64,128,256,512]\n",
    "bottlenecks = None\n",
    "img_channels = 3\n",
    "first_kernel_size = 7\n",
    "\n",
    "k = ResNetBase(n_blocks, n_channels, bottlenecks, img_channels, first_kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(k(data))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
